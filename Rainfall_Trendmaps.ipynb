{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable \n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "import h5py  \n",
    "from astropy.time import Time\n",
    "import os\n",
    "import glob\n",
    "from osgeo import gdal\n",
    "import scipy.ndimage\n",
    "import rasterio as rio\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import earthpy.mask as em\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H19V07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes coordinate and returns corresponding index of IMEG list.\n",
    "def latitude_index(x):\n",
    "    index = round(((-89.95 - x)*-10), 1)\n",
    "    index = int(index)\n",
    "    return index\n",
    "\n",
    "def longitude_index(x):\n",
    "    index = round(((-179.95 - x)*-10), 1)\n",
    "    index = int(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directory, and change working directory - plug in D:\n",
    "inDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\H19_V07_arrays\\\\\"   # I should change this so I can work from github?\n",
    "os.chdir(inDir)  # Change to working directory\n",
    "outDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\" # Create and set output directory\n",
    "if not os.path.exists(outDir): os.makedirs(outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first rainfall file\n",
    "H19V07_2002 = glob.glob('*2002*')\n",
    "H19V07_2003 = glob.glob('*2003*')\n",
    "H19V07_2004 = glob.glob('*2004*')\n",
    "H19V07_2005 = glob.glob('*2005*')\n",
    "H19V07_2006 = glob.glob('*2006*')\n",
    "H19V07_2007 = glob.glob('*2007*')\n",
    "H19V07_2008 = glob.glob('*2008*')\n",
    "H19V07_2009 = glob.glob('*2009*')\n",
    "H19V07_2010 = glob.glob('*2010*')\n",
    "H19V07_2011 = glob.glob('*2011*')\n",
    "H19V07_2012 = glob.glob('*2012*')\n",
    "H19V07_2013 = glob.glob('*2013*')\n",
    "H19V07_2014 = glob.glob('*2014*')\n",
    "H19V07_2015 = glob.glob('*2015*')\n",
    "H19V07_2016 = glob.glob('*2016*')\n",
    "H19V07_2017 = glob.glob('*2017*')\n",
    "H19V07_2018 = glob.glob('*2018*')\n",
    "H19V07_2019 = glob.glob('*2019*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H19V07_total_2002 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2002)):\n",
    "    file = pd.read_csv(H19V07_2002[NUMBER], header= None)\n",
    "    H19V07_total_2002 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2002 = H19V07_total_2002 / len(H19V07_2002)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2003 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2003)):\n",
    "    file = pd.read_csv(H19V07_2003[NUMBER], header= None)\n",
    "    H19V07_total_2003 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2003 = H19V07_total_2003 / len(H19V07_2003)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2004 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2004)):\n",
    "    file = pd.read_csv(H19V07_2004[NUMBER], header= None)\n",
    "    H19V07_total_2004 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2004 = H19V07_total_2004 / len(H19V07_2004)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2005 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2005)):\n",
    "    file = pd.read_csv(H19V07_2005[NUMBER], header= None)\n",
    "    H19V07_total_2005 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2005 = H19V07_total_2005 / len(H19V07_2005)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2006 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2006)):\n",
    "    file = pd.read_csv(H19V07_2006[NUMBER], header= None)\n",
    "    H19V07_total_2006 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2006 = H19V07_total_2006 / len(H19V07_2006)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2007 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2007)):\n",
    "    file = pd.read_csv(H19V07_2007[NUMBER], header= None)\n",
    "    H19V07_total_2007 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2007 = H19V07_total_2007 / len(H19V07_2007)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2008 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2008)):\n",
    "    file = pd.read_csv(H19V07_2008[NUMBER], header= None)\n",
    "    H19V07_total_2008 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2008 = H19V07_total_2008 / len(H19V07_2008)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2009 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2009)):\n",
    "    file = pd.read_csv(H19V07_2009[NUMBER], header= None)\n",
    "    H19V07_total_2009 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2009 = H19V07_total_2009 / len(H19V07_2009)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2010 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2010)):\n",
    "    file = pd.read_csv(H19V07_2010[NUMBER], header= None)\n",
    "    H19V07_total_2010 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2010 = H19V07_total_2010 / len(H19V07_2010)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2011 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2011)):\n",
    "    file = pd.read_csv(H19V07_2011[NUMBER], header= None)\n",
    "    H19V07_total_2011 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2011 = H19V07_total_2011 / len(H19V07_2011)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2012 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2012)):\n",
    "    file = pd.read_csv(H19V07_2012[NUMBER], header= None)\n",
    "    H19V07_total_2012 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2012 = H19V07_total_2012 / len(H19V07_2012)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2013 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2013)):\n",
    "    file = pd.read_csv(H19V07_2013[NUMBER], header= None)\n",
    "    H19V07_total_2013 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2013 = H19V07_total_2013 / len(H19V07_2013)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2014 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2014)):\n",
    "    file = pd.read_csv(H19V07_2014[NUMBER], header= None)\n",
    "    H19V07_total_2014 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2014 = H19V07_total_2014 / len(H19V07_2014)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2015 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2015)):\n",
    "    file = pd.read_csv(H19V07_2015[NUMBER], header= None)\n",
    "    H19V07_total_2015 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2015 = H19V07_total_2015 / len(H19V07_2015)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2016 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2016)):\n",
    "    file = pd.read_csv(H19V07_2016[NUMBER], header= None)\n",
    "    H19V07_total_2016 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2016 = H19V07_total_2016 / len(H19V07_2016)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2017 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2017)):\n",
    "    file = pd.read_csv(H19V07_2017[NUMBER], header= None)\n",
    "    H19V07_total_2017 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2017 = H19V07_total_2017 / len(H19V07_2017)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2018 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2018)):\n",
    "    file = pd.read_csv(H19V07_2018[NUMBER], header= None)\n",
    "    H19V07_total_2018 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2018 = H19V07_total_2018 / len(H19V07_2018)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V07_total_2019 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V07_2019)):\n",
    "    file = pd.read_csv(H19V07_2019[NUMBER], header= None)\n",
    "    H19V07_total_2019 += file\n",
    "    NUMBER += 1\n",
    "H19V07_average_2019 = H19V07_total_2019 / len(H19V07_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2002.csv\", H19V07_average_2002, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2003.csv\", H19V07_average_2003, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2004.csv\", H19V07_average_2004, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2005.csv\", H19V07_average_2005, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2006.csv\", H19V07_average_2006, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2007.csv\", H19V07_average_2007, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2008.csv\", H19V07_average_2008, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2009.csv\", H19V07_average_2009, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2010.csv\", H19V07_average_2010, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2011.csv\", H19V07_average_2011, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2012.csv\", H19V07_average_2012, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2013.csv\", H19V07_average_2013, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2014.csv\", H19V07_average_2014, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2015.csv\", H19V07_average_2015, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2016.csv\", H19V07_average_2016, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2017.csv\", H19V07_average_2017, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2018.csv\", H19V07_average_2018, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V07\\\\H19V07_average_2019.csv\", H19V07_average_2019, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H19V08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directory, and change working directory - plug in D:\n",
    "inDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\H19_V08_arrays\\\\\"   # I should change this so I can work from github?\n",
    "os.chdir(inDir)  # Change to working directory\n",
    "outDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\" # Create and set output directory\n",
    "if not os.path.exists(outDir): os.makedirs(outDir)\n",
    "    \n",
    "    \n",
    "# select first rainfall file\n",
    "H19V08_2002 = glob.glob('*2002*')\n",
    "H19V08_2003 = glob.glob('*2003*')\n",
    "H19V08_2004 = glob.glob('*2004*')\n",
    "H19V08_2005 = glob.glob('*2005*')\n",
    "H19V08_2006 = glob.glob('*2006*')\n",
    "H19V08_2007 = glob.glob('*2007*')\n",
    "H19V08_2008 = glob.glob('*2008*')\n",
    "H19V08_2009 = glob.glob('*2009*')\n",
    "H19V08_2010 = glob.glob('*2010*')\n",
    "H19V08_2011 = glob.glob('*2011*')\n",
    "H19V08_2012 = glob.glob('*2012*')\n",
    "H19V08_2013 = glob.glob('*2013*')\n",
    "H19V08_2014 = glob.glob('*2014*')\n",
    "H19V08_2015 = glob.glob('*2015*')\n",
    "H19V08_2016 = glob.glob('*2016*')\n",
    "H19V08_2017 = glob.glob('*2017*')\n",
    "H19V08_2018 = glob.glob('*2018*')\n",
    "H19V08_2019 = glob.glob('*2019*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H19V08_total_2002 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2002)):\n",
    "    file = pd.read_csv(H19V08_2002[NUMBER], header= None)\n",
    "    H19V08_total_2002 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2002 = H19V08_total_2002 / len(H19V08_2002)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2003 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2003)):\n",
    "    file = pd.read_csv(H19V08_2003[NUMBER], header= None)\n",
    "    H19V08_total_2003 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2003 = H19V08_total_2003 / len(H19V08_2003)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2004 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2004)):\n",
    "    file = pd.read_csv(H19V08_2004[NUMBER], header= None)\n",
    "    H19V08_total_2004 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2004 = H19V08_total_2004 / len(H19V08_2004)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2005 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2005)):\n",
    "    file = pd.read_csv(H19V08_2005[NUMBER], header= None)\n",
    "    H19V08_total_2005 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2005 = H19V08_total_2005 / len(H19V08_2005)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2006 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2006)):\n",
    "    file = pd.read_csv(H19V08_2006[NUMBER], header= None)\n",
    "    H19V08_total_2006 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2006 = H19V08_total_2006 / len(H19V08_2006)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2007 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2007)):\n",
    "    file = pd.read_csv(H19V08_2007[NUMBER], header= None)\n",
    "    H19V08_total_2007 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2007 = H19V08_total_2007 / len(H19V08_2007)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2008 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2008)):\n",
    "    file = pd.read_csv(H19V08_2008[NUMBER], header= None)\n",
    "    H19V08_total_2008 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2008 = H19V08_total_2008 / len(H19V08_2008)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2009 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2009)):\n",
    "    file = pd.read_csv(H19V08_2009[NUMBER], header= None)\n",
    "    H19V08_total_2009 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2009 = H19V08_total_2009 / len(H19V08_2009)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2010 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2010)):\n",
    "    file = pd.read_csv(H19V08_2010[NUMBER], header= None)\n",
    "    H19V08_total_2010 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2010 = H19V08_total_2010 / len(H19V08_2010)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2011 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2011)):\n",
    "    file = pd.read_csv(H19V08_2011[NUMBER], header= None)\n",
    "    H19V08_total_2011 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2011 = H19V08_total_2011 / len(H19V08_2011)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2012 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2012)):\n",
    "    file = pd.read_csv(H19V08_2012[NUMBER], header= None)\n",
    "    H19V08_total_2012 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2012 = H19V08_total_2012 / len(H19V08_2012)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2013 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2013)):\n",
    "    file = pd.read_csv(H19V08_2013[NUMBER], header= None)\n",
    "    H19V08_total_2013 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2013 = H19V08_total_2013 / len(H19V08_2013)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2014 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2014)):\n",
    "    file = pd.read_csv(H19V08_2014[NUMBER], header= None)\n",
    "    H19V08_total_2014 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2014 = H19V08_total_2014 / len(H19V08_2014)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2015 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2015)):\n",
    "    file = pd.read_csv(H19V08_2015[NUMBER], header= None)\n",
    "    H19V08_total_2015 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2015 = H19V08_total_2015 / len(H19V08_2015)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2016 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2016)):\n",
    "    file = pd.read_csv(H19V08_2016[NUMBER], header= None)\n",
    "    H19V08_total_2016 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2016 = H19V08_total_2016 / len(H19V08_2016)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2017 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2017)):\n",
    "    file = pd.read_csv(H19V08_2017[NUMBER], header= None)\n",
    "    H19V08_total_2017 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2017 = H19V08_total_2017 / len(H19V08_2017)\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2018 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2018)):\n",
    "    file = pd.read_csv(H19V08_2018[NUMBER], header= None)\n",
    "    H19V08_total_2018 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2018 = H19V08_total_2018 / len(H19V08_2018)\n",
    "\n",
    "\n",
    "NUMBER = 0\n",
    "H19V08_total_2019 = np.zeros((2400, 2400))\n",
    "for i in range(len(H19V08_2019)):\n",
    "    file = pd.read_csv(H19V08_2019[NUMBER], header= None)\n",
    "    H19V08_total_2019 += file\n",
    "    NUMBER += 1\n",
    "H19V08_average_2019 = H19V08_total_2019 / len(H19V08_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2002.csv\", H19V08_average_2002, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2003.csv\", H19V08_average_2003, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2004.csv\", H19V08_average_2004, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2005.csv\", H19V08_average_2005, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2006.csv\", H19V08_average_2006, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2007.csv\", H19V08_average_2007, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2008.csv\", H19V08_average_2008, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2009.csv\", H19V08_average_2009, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2010.csv\", H19V08_average_2010, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2011.csv\", H19V08_average_2011, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2012.csv\", H19V08_average_2012, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2013.csv\", H19V08_average_2013, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2014.csv\", H19V08_average_2014, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2015.csv\", H19V08_average_2015, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2016.csv\", H19V08_average_2016, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2017.csv\", H19V08_average_2017, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2018.csv\", H19V08_average_2018, delimiter=\",\")\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H19V08\\\\H19V08_average_2019.csv\", H19V08_average_2019, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directory, and change working directory - plug in D:\n",
    "inDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\H19_V08_arrays\\\\\"   # I should change this so I can work from github?\n",
    "os.chdir(inDir)  # Change to working directory\n",
    "outDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\" # Create and set output directory\n",
    "if not os.path.exists(outDir): os.makedirs(outDir)\n",
    "    \n",
    "    \n",
    "# select first rainfall file\n",
    "H20V07_2002 = glob.glob('*2002*')\n",
    "H20V07_2003 = glob.glob('*2003*')\n",
    "H20V07_2004 = glob.glob('*2004*')\n",
    "H20V07_2005 = glob.glob('*2005*')\n",
    "H20V07_2006 = glob.glob('*2006*')\n",
    "H20V07_2007 = glob.glob('*2007*')\n",
    "H20V07_2008 = glob.glob('*2008*')\n",
    "H20V07_2009 = glob.glob('*2009*')\n",
    "H20V07_2010 = glob.glob('*2010*')\n",
    "H20V07_2011 = glob.glob('*2011*')\n",
    "H20V07_2012 = glob.glob('*2012*')\n",
    "H20V07_2013 = glob.glob('*2013*')\n",
    "H20V07_2014 = glob.glob('*2014*')\n",
    "H20V07_2015 = glob.glob('*2015*')\n",
    "H20V07_2016 = glob.glob('*2016*')\n",
    "H20V07_2017 = glob.glob('*2017*')\n",
    "H20V07_2018 = glob.glob('*2018*')\n",
    "H20V07_2019 = glob.glob('*2019*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2002 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2002)):\n",
    "    file = pd.read_csv(H20V07_2002[NUMBER], header= None)\n",
    "    H20V07_total_2002 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2002 = H20V07_total_2002 / len(H20V07_2002)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2002.csv\", H20V07_average_2002, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2003 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2003)):\n",
    "    file = pd.read_csv(H20V07_2003[NUMBER], header= None)\n",
    "    H20V07_total_2003 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2003 = H20V07_total_2003 / len(H20V07_2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2003.csv\", H20V07_average_2003, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2004 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2004)):\n",
    "    file = pd.read_csv(H20V07_2004[NUMBER], header= None)\n",
    "    H20V07_total_2004 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2004 = H20V07_total_2004 / len(H20V07_2004)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2004.csv\", H20V07_average_2004, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2005 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2005)):\n",
    "    file = pd.read_csv(H20V07_2005[NUMBER], header= None)\n",
    "    H20V07_total_2005 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2005 = H20V07_total_2005 / len(H20V07_2005)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2005.csv\", H20V07_average_2005, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2006 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2006)):\n",
    "    file = pd.read_csv(H20V07_2006[NUMBER], header= None)\n",
    "    H20V07_total_2006 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2006 = H20V07_total_2006 / len(H20V07_2006)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2006.csv\", H20V07_average_2006, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2007 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2007)):\n",
    "    file = pd.read_csv(H20V07_2007[NUMBER], header= None)\n",
    "    H20V07_total_2007 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2007 = H20V07_total_2007 / len(H20V07_2007)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2007.csv\", H20V07_average_2007, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2008 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2008)):\n",
    "    file = pd.read_csv(H20V07_2008[NUMBER], header= None)\n",
    "    H20V07_total_2008 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2008 = H20V07_total_2008 / len(H20V07_2008)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2008.csv\", H20V07_average_2008, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2009 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2009)):\n",
    "    file = pd.read_csv(H20V07_2009[NUMBER], header= None)\n",
    "    H20V07_total_2009 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2009 = H20V07_total_2009 / len(H20V07_2009)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2009.csv\", H20V07_average_2009, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2010 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2010)):\n",
    "    file = pd.read_csv(H20V07_2010[NUMBER], header= None)\n",
    "    H20V07_total_2010 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2010 = H20V07_total_2010 / len(H20V07_2010)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2010.csv\", H20V07_average_2010, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2011 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2011)):\n",
    "    file = pd.read_csv(H20V07_2011[NUMBER], header= None)\n",
    "    H20V07_total_2011 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2011 = H20V07_total_2011 / len(H20V07_2011)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2011.csv\", H20V07_average_2011, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2012 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2012)):\n",
    "    file = pd.read_csv(H20V07_2012[NUMBER], header= None)\n",
    "    H20V07_total_2012 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2012 = H20V07_total_2012 / len(H20V07_2012)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2012.csv\", H20V07_average_2012, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2013 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2013)):\n",
    "    file = pd.read_csv(H20V07_2013[NUMBER], header= None)\n",
    "    H20V07_total_2013 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2013 = H20V07_total_2013 / len(H20V07_2013)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2013.csv\", H20V07_average_2013, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2014 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2014)):\n",
    "    file = pd.read_csv(H20V07_2014[NUMBER], header= None)\n",
    "    H20V07_total_2014 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2014 = H20V07_total_2014 / len(H20V07_2014)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2014.csv\", H20V07_average_2014, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2015 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2015)):\n",
    "    file = pd.read_csv(H20V07_2015[NUMBER], header= None)\n",
    "    H20V07_total_2015 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2015 = H20V07_total_2015 / len(H20V07_2015)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2015.csv\", H20V07_average_2015, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2016 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2016)):\n",
    "    file = pd.read_csv(H20V07_2016[NUMBER], header= None)\n",
    "    H20V07_total_2016 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2016 = H20V07_total_2016 / len(H20V07_2016)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2016.csv\", H20V07_average_2016, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2017 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2017)):\n",
    "    file = pd.read_csv(H20V07_2017[NUMBER], header= None)\n",
    "    H20V07_total_2017 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2017 = H20V07_total_2017 / len(H20V07_2017)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2017.csv\", H20V07_average_2017, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2018 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2018)):\n",
    "    file = pd.read_csv(H20V07_2018[NUMBER], header= None)\n",
    "    H20V07_total_2018 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2018 = H20V07_total_2018 / len(H20V07_2018)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2018.csv\", H20V07_average_2018, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V07_total_2019 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V07_2019)):\n",
    "    file = pd.read_csv(H20V07_2019[NUMBER], header= None)\n",
    "    H20V07_total_2019 += file\n",
    "    NUMBER += 1\n",
    "H20V07_average_2019 = H20V07_total_2019 / len(H20V07_2019)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V07\\\\H20V07_average_2019.csv\", H20V07_average_2019, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input directory, and change working directory - plug in D:\n",
    "inDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\H19_V08_arrays\\\\\"   # I should change this so I can work from github?\n",
    "os.chdir(inDir)  # Change to working directory\n",
    "outDir = \"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\" # Create and set output directory\n",
    "if not os.path.exists(outDir): os.makedirs(outDir)\n",
    "    \n",
    "    \n",
    "# select first rainfall file\n",
    "H20V08_2002 = glob.glob('*2002*')\n",
    "H20V08_2003 = glob.glob('*2003*')\n",
    "H20V08_2004 = glob.glob('*2004*')\n",
    "H20V08_2005 = glob.glob('*2005*')\n",
    "H20V08_2006 = glob.glob('*2006*')\n",
    "H20V08_2007 = glob.glob('*2007*')\n",
    "H20V08_2008 = glob.glob('*2008*')\n",
    "H20V08_2009 = glob.glob('*2009*')\n",
    "H20V08_2010 = glob.glob('*2010*')\n",
    "H20V08_2011 = glob.glob('*2011*')\n",
    "H20V08_2012 = glob.glob('*2012*')\n",
    "H20V08_2013 = glob.glob('*2013*')\n",
    "H20V08_2014 = glob.glob('*2014*')\n",
    "H20V08_2015 = glob.glob('*2015*')\n",
    "H20V08_2016 = glob.glob('*2016*')\n",
    "H20V08_2017 = glob.glob('*2017*')\n",
    "H20V08_2018 = glob.glob('*2018*')\n",
    "H20V08_2019 = glob.glob('*2019*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2002 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2002)):\n",
    "    file = pd.read_csv(H20V08_2002[NUMBER], header= None)\n",
    "    H20V08_total_2002 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2002 = H20V08_total_2002 / len(H20V08_2002)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2002.csv\", H20V08_average_2002, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2003 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2003)):\n",
    "    file = pd.read_csv(H20V08_2003[NUMBER], header= None)\n",
    "    H20V08_total_2003 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2003 = H20V08_total_2003 / len(H20V08_2003)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2003.csv\", H20V08_average_2003, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2004 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2004)):\n",
    "    file = pd.read_csv(H20V08_2004[NUMBER], header= None)\n",
    "    H20V08_total_2004 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2004 = H20V08_total_2004 / len(H20V08_2004)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2004.csv\", H20V08_average_2004, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2005 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2005)):\n",
    "    file = pd.read_csv(H20V08_2005[NUMBER], header= None)\n",
    "    H20V08_total_2005 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2005 = H20V08_total_2005 / len(H20V08_2005)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2005.csv\", H20V08_average_2005, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2006 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2006)):\n",
    "    file = pd.read_csv(H20V08_2006[NUMBER], header= None)\n",
    "    H20V08_total_2006 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2006 = H20V08_total_2006 / len(H20V08_2006)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2006.csv\", H20V08_average_2006, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2007 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2007)):\n",
    "    file = pd.read_csv(H20V08_2007[NUMBER], header= None)\n",
    "    H20V08_total_2007 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2007 = H20V08_total_2007 / len(H20V08_2007)\n",
    "\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2007.csv\", H20V08_average_2007, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2008 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2008)):\n",
    "    file = pd.read_csv(H20V08_2008[NUMBER], header= None)\n",
    "    H20V08_total_2008 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2008 = H20V08_total_2008 / len(H20V08_2008)\n",
    "\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2008.csv\", H20V08_average_2008, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2009 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2009)):\n",
    "    file = pd.read_csv(H20V08_2009[NUMBER], header= None)\n",
    "    H20V08_total_2009 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2009 = H20V08_total_2009 / len(H20V08_2009)\n",
    "\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2009.csv\", H20V08_average_2009, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2010 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2010)):\n",
    "    file = pd.read_csv(H20V08_2010[NUMBER], header= None)\n",
    "    H20V08_total_2010 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2010 = H20V08_total_2010 / len(H20V08_2010)\n",
    "\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2010.csv\", H20V08_average_2010, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2011 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2011)):\n",
    "    file = pd.read_csv(H20V08_2011[NUMBER], header= None)\n",
    "    H20V08_total_2011 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2011 = H20V08_total_2011 / len(H20V08_2011)\n",
    "\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2011.csv\", H20V08_average_2011, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2012 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2012)):\n",
    "    file = pd.read_csv(H20V08_2012[NUMBER], header= None)\n",
    "    H20V08_total_2012 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2012 = H20V08_total_2012 / len(H20V08_2012)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2012.csv\", H20V08_average_2012, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2013 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2013)):\n",
    "    file = pd.read_csv(H20V08_2013[NUMBER], header= None)\n",
    "    H20V08_total_2013 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2013 = H20V08_total_2013 / len(H20V08_2013)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2013.csv\", H20V08_average_2013, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2014 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2014)):\n",
    "    file = pd.read_csv(H20V08_2014[NUMBER], header= None)\n",
    "    H20V08_total_2014 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2014 = H20V08_total_2014 / len(H20V08_2014)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2014.csv\", H20V08_average_2014, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2015 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2015)):\n",
    "    file = pd.read_csv(H20V08_2015[NUMBER], header= None)\n",
    "    H20V08_total_2015 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2015 = H20V08_total_2015 / len(H20V08_2015)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2015.csv\", H20V08_average_2015, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2016 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2016)):\n",
    "    file = pd.read_csv(H20V08_2016[NUMBER], header= None)\n",
    "    H20V08_total_2016 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2016 = H20V08_total_2016 / len(H20V08_2016)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2016.csv\", H20V08_average_2016, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2017 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2017)):\n",
    "    file = pd.read_csv(H20V08_2017[NUMBER], header= None)\n",
    "    H20V08_total_2017 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2017 = H20V08_total_2017 / len(H20V08_2017)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2017.csv\", H20V08_average_2017, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2018 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2018)):\n",
    "    file = pd.read_csv(H20V08_2018[NUMBER], header= None)\n",
    "    H20V08_total_2018 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2018 = H20V08_total_2018 / len(H20V08_2018)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2018.csv\", H20V08_average_2018, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 0\n",
    "H20V08_total_2019 = np.zeros((2400, 2400))\n",
    "for i in range(len(H20V08_2019)):\n",
    "    file = pd.read_csv(H20V08_2019[NUMBER], header= None)\n",
    "    H20V08_total_2019 += file\n",
    "    NUMBER += 1\n",
    "H20V08_average_2019 = H20V08_total_2019 / len(H20V08_2019)\n",
    "np.savetxt(\"D:\\\\masters_data\\\\output\\\\csv\\\\Rainfall\\\\Trendmaps\\\\H20V08\\\\H20V08_average_2019.csv\", H20V08_average_2019, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
